{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit"
  },
  "interpreter": {
   "hash": "78e3285aa314e3b9623a78f469f137e078bd7f6e3d31f66d2467543bc9a33ac2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as FF\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "source": [
    "# Generator"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, z_dim=20):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(z_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(1024, 7*7*128),\n",
    "            nn.BatchNorm1d(7*7*128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=128,\n",
    "                out_channels=64,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.last = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=64,\n",
    "                out_channels=1,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1),\n",
    "                nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.layer1(z)\n",
    "        out = self.layer2(out)\n",
    "\n",
    "        # 転置畳み込み層に入れるためにテンソルの形を整形\n",
    "        out = out.view(z.shape[0], 128, 7, 7)\n",
    "        out = self.layer3(out)\n",
    "        out = self.last(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.518125\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-07-09T13:54:24.647412</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.4.1, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 248.518125 \r\nL 251.565 248.518125 \r\nL 251.565 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 26.925 224.64 \r\nL 244.365 224.64 \r\nL 244.365 7.2 \r\nL 26.925 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p3bd5f0501e)\">\r\n    <image height=\"218\" id=\"image042939f05d\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.64\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m36e33b6bec\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#m36e33b6bec\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(27.626607 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 2034 4250 \r\nQ 1547 4250 1301 3770 \r\nQ 1056 3291 1056 2328 \r\nQ 1056 1369 1301 889 \r\nQ 1547 409 2034 409 \r\nQ 2525 409 2770 889 \r\nQ 3016 1369 3016 2328 \r\nQ 3016 3291 2770 3770 \r\nQ 2525 4250 2034 4250 \r\nz\r\nM 2034 4750 \r\nQ 2819 4750 3233 4129 \r\nQ 3647 3509 3647 2328 \r\nQ 3647 1150 3233 529 \r\nQ 2819 -91 2034 -91 \r\nQ 1250 -91 836 529 \r\nQ 422 1150 422 2328 \r\nQ 422 3509 836 4129 \r\nQ 1250 4750 2034 4750 \r\nz\r\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#m36e33b6bec\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(66.455179 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 691 4666 \r\nL 3169 4666 \r\nL 3169 4134 \r\nL 1269 4134 \r\nL 1269 2991 \r\nQ 1406 3038 1543 3061 \r\nQ 1681 3084 1819 3084 \r\nQ 2600 3084 3056 2656 \r\nQ 3513 2228 3513 1497 \r\nQ 3513 744 3044 326 \r\nQ 2575 -91 1722 -91 \r\nQ 1428 -91 1123 -41 \r\nQ 819 9 494 109 \r\nL 494 744 \r\nQ 775 591 1075 516 \r\nQ 1375 441 1709 441 \r\nQ 2250 441 2565 725 \r\nQ 2881 1009 2881 1497 \r\nQ 2881 1984 2565 2268 \r\nQ 2250 2553 1709 2553 \r\nQ 1456 2553 1204 2497 \r\nQ 953 2441 691 2322 \r\nL 691 4666 \r\nz\r\n\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#m36e33b6bec\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(102.1025 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 794 531 \r\nL 1825 531 \r\nL 1825 4091 \r\nL 703 3866 \r\nL 703 4441 \r\nL 1819 4666 \r\nL 2450 4666 \r\nL 2450 531 \r\nL 3481 531 \r\nL 3481 0 \r\nL 794 0 \r\nL 794 531 \r\nz\r\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#m36e33b6bec\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(140.931071 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#m36e33b6bec\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(179.759643 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 1228 531 \r\nL 3431 531 \r\nL 3431 0 \r\nL 469 0 \r\nL 469 531 \r\nQ 828 903 1448 1529 \r\nQ 2069 2156 2228 2338 \r\nQ 2531 2678 2651 2914 \r\nQ 2772 3150 2772 3378 \r\nQ 2772 3750 2511 3984 \r\nQ 2250 4219 1831 4219 \r\nQ 1534 4219 1204 4116 \r\nQ 875 4013 500 3803 \r\nL 500 4441 \r\nQ 881 4594 1212 4672 \r\nQ 1544 4750 1819 4750 \r\nQ 2544 4750 2975 4387 \r\nQ 3406 4025 3406 3419 \r\nQ 3406 3131 3298 2873 \r\nQ 3191 2616 2906 2266 \r\nQ 2828 2175 2409 1742 \r\nQ 1991 1309 1228 531 \r\nz\r\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#m36e33b6bec\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(218.588214 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m869f30a3cb\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m869f30a3cb\" y=\"11.082857\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(13.5625 14.882076)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m869f30a3cb\" y=\"49.911429\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(13.5625 53.710647)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m869f30a3cb\" y=\"88.74\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(7.2 92.539219)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m869f30a3cb\" y=\"127.568571\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(7.2 131.36779)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m869f30a3cb\" y=\"166.397143\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(7.2 170.196362)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m869f30a3cb\" y=\"205.225714\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(7.2 209.024933)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 26.925 224.64 \r\nL 26.925 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 244.365 224.64 \r\nL 244.365 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 26.925 224.64 \r\nL 244.365 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 26.925 7.2 \r\nL 244.365 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p3bd5f0501e\">\r\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "G = Generator(z_dim=20)\n",
    "G.train()\n",
    "\n",
    "input_z = torch.randn(2, 20)\n",
    "\n",
    "fake_images = G(input_z)\n",
    "img_transformed = fake_images[0][0].detach().numpy()\n",
    "plt.imshow(img_transformed, 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# Discriminator"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, z_dim=20):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.x_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1,64,kernel_size=4,\n",
    "                    stride=2,padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True)\n",
    "        )\n",
    "\n",
    "        self.x_layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64,64,kernel_size=4,\n",
    "                    stride=2,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1,inplace=True)\n",
    "        )\n",
    "\n",
    "        self.z_layer1 = nn.Linear(z_dim, 512)\n",
    "\n",
    "        self.last1 = nn.Sequential(\n",
    "            nn.Linear(3648,1024),\n",
    "            nn.LeakyReLU(0.1, inplace=True)\n",
    "        )\n",
    "\n",
    "        self.last2 = nn.Linear(1024,1)\n",
    "\n",
    "    def forward(self, x, z):\n",
    "\n",
    "        x_out = self.x_layer1(x)\n",
    "        x_out = self.x_layer2(x_out)\n",
    "\n",
    "        z = z.view(z.shape[0], -1)\n",
    "        z_out = self.z_layer1(z)\n",
    "\n",
    "        x_out = x_out.view(-1, 64 * 7 * 7)\n",
    "        out = torch.cat([x_out, z_out], dim=1)\n",
    "        out = self.last1(out)\n",
    "\n",
    "        feature = out\n",
    "\n",
    "        feature = feature.view(feature.size()[0], -1)\n",
    "\n",
    "        out = self.last2(out)\n",
    "\n",
    "        return out, feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.5579],\n        [0.5507]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "D = Discriminator(z_dim=20)\n",
    "\n",
    "input_z = torch.randn(2, 20)\n",
    "fake_images = G(input_z)\n",
    "\n",
    "fake_images = G(input_z)\n",
    "\n",
    "d_out, _ = D(fake_images, input_z)\n",
    "\n",
    "print(nn.Sigmoid()(d_out))"
   ]
  },
  {
   "source": [
    "# Encoder"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, z_dim=20):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1,32,kernel_size=3,\n",
    "                    stride=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True)\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32,64,kernel_size=3,\n",
    "                    stride=2,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1, inplace=True)\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64,128,kernel_size=3,\n",
    "                    stride=2,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1, inplace=True)\n",
    "        )\n",
    "\n",
    "        self.last = nn.Linear(128*7*7,z_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "\n",
    "        out = out.view(-1,128*7*7)\n",
    "        out = self.last(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([2, 20])\ntensor([[ 0.0690,  0.2678, -0.4826, -0.1528,  0.1303, -0.2641, -0.4296,  0.7629,\n         -0.0215,  0.7813,  0.0345,  0.1489, -1.2330,  0.1028, -0.0897,  0.1279,\n         -0.2455, -1.1458, -0.1089, -0.3185],\n        [-0.1693, -0.5945, -0.0973, -0.7662,  0.0185, -0.1420, -0.1820,  0.4278,\n         -0.1888,  0.1832, -0.0620, -0.2926, -0.1563, -0.6806, -0.3959, -0.0669,\n         -0.0885, -0.7621,  0.2679, -0.6619]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "E = Encoder(z_dim=20)\n",
    "\n",
    "x = fake_images\n",
    "\n",
    "z = E(x)\n",
    "\n",
    "print(z.shape)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datapath_list():\n",
    "\n",
    "    train_img_list = list()\n",
    "\n",
    "    for img_idx in range(200):\n",
    "        img_path = \"./data/img_78_28size/img_7_\" + str(img_idx)+'.jpg'\n",
    "        train_img_list.append(img_path)\n",
    "\n",
    "        img_path = \"./data/img_78_28size/img_8_\" + str(img_idx)+'.jpg'\n",
    "        train_img_list.append(img_path)\n",
    "\n",
    "    return train_img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransform():\n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        self.data_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean,std)\n",
    "        ])\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return self.data_transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN_Img_Dataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, file_list, transform):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        img_path = self.file_list[index]\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        img_transformed = self.transform(img)\n",
    "\n",
    "        return img_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "train_img_list = make_datapath_list()\n",
    "\n",
    "mean = (0.5,)\n",
    "std = (0.5,)\n",
    "train_dataset = GAN_Img_Dataset(\n",
    "    file_list = train_img_list, transform=ImageTransform(mean, std)\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "batch_iterator = iter(train_dataloader)\n",
    "imges = next(batch_iterator)\n",
    "print(imges.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "torch.cuda.is_available()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(G, D, E, dataloader, num_epochs):\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"device:\",device)\n",
    "\n",
    "    lr_ge = 0.0001\n",
    "    lr_d = 0.0001/4\n",
    "    beta1, beta2 = 0.5, 0.999\n",
    "    g_optimizer = torch.optim.Adam(G.parameters(), lr_ge, [beta1,beta2])\n",
    "    e_optimizer = torch.optim.Adam(E.parameters(), lr_ge, [beta1,beta2])\n",
    "    d_optimizer = torch.optim.Adam(D.parameters(), lr_ge, [beta1,beta2])\n",
    "\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "\n",
    "    z_dim = 20\n",
    "    mini_batch_size = 64\n",
    "\n",
    "    G.to(device)\n",
    "    E.to(device)\n",
    "    D.to(device)\n",
    "\n",
    "    G.train()\n",
    "    E.train()\n",
    "    D.train()\n",
    "\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    num_train_imgs = len(dataloader.dataset)\n",
    "    batch_size = dataloader.batch_size\n",
    "\n",
    "    iteration = 1\n",
    "    logs = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        t_epoch_start = time.time()\n",
    "        epoch_g_loss = 0.0\n",
    "        epoch_e_loss = 0.0\n",
    "        epoch_d_loss = 0.0\n",
    "\n",
    "        print(\"-------------------\")\n",
    "        print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "        print(\"-------------------\")\n",
    "        print(\"train\")\n",
    "\n",
    "        for imges in dataloader:\n",
    "\n",
    "\n",
    "            if imges.size()[0] == 1:\n",
    "                continue\n",
    "\n",
    "\n",
    "            mini_batch_size = imges.size()[0]\n",
    "            label_real = torch.full((mini_batch_size), 1).to(device)\n",
    "            label_fake = torch.full((mini_batch_size), 0).to(device)\n",
    "\n",
    "            imges = imges.to(device)\n",
    "\n",
    "            # Discriminator\n",
    "\n",
    "            z_out_real = E(imges)\n",
    "            d_out_real, _ = D(imges, z_out_real)\n",
    "\n",
    "            input_z = torch.randn(mini_batch_size, z_dim).to(device)\n",
    "\n",
    "            fake_images = G(input_z)\n",
    "            d_out_fake, _ = D(fake_images, input_z)\n",
    "\n",
    "            d_loss_real = criterion(d_out_real.view(-1), label_real)\n",
    "            d_loss_fake = criterion(d_out_fake.view(-1),label_fake)\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "            \n",
    "            d_optimizer.zero_grad()\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            # Generator\n",
    "            input_z = torch.randn(mini_batch_size, z_dim).to(device)\n",
    "            fake_images = G(input_z)\n",
    "            d_out_fake, _ = D(fake_images, input_z)\n",
    "\n",
    "            g_loss = criterion(d_out_fake.view(-1), label_real)\n",
    "\n",
    "            g_optimizer.zero_grad()\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "            # Encoder\n",
    "            z_out_real = E(imges)\n",
    "            d_out_real, _ = D(imges, z_out_real)\n",
    "\n",
    "            e_loss = criterion(d_out_real.view(-1), label_fake)\n",
    "\n",
    "            e_optimizer.zero_grad()\n",
    "            e_loss.backward()\n",
    "            e_optimizer.step()\n",
    "\n",
    "\n",
    "            epoch_d_loss += d_loss.item()\n",
    "            epoch_g_loss += g_loss.item()\n",
    "            epoch_e_loss += e_loss.item()\n",
    "            iteration += 1\n",
    "\n",
    "\n",
    "        t_epoch_finish = time.time()\n",
    "        print(\"-------------------\")\n",
    "        print(f\"epoch {epoch}|| Epoch D loss:{epoch_d_loss/batch_size:.4f} || Epoch G loss:{epoch_g_loss/batch_size:.4f} || Epoch E loss:{epoch_e_loss/batch_size:.4f}\")\n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "        print(\"Iteration:\",iteration)\n",
    "\n",
    "        return G ,D , E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (x_layer1): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (x_layer2): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (z_layer1): Linear(in_features=20, out_features=512, bias=True)\n",
       "  (last1): Sequential(\n",
       "    (0): Linear(in_features=3648, out_features=1024, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (last2): Linear(in_features=1024, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "G.apply(weights_init)\n",
    "E.apply(weights_init)\n",
    "D.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}